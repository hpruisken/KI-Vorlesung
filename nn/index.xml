<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NN: Einführung in Neuronale Netze on </title>
    <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn.html</link>
    <description>Recent content in NN: Einführung in Neuronale Netze on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language><atom:link href="https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NN1 - Das Perzeptron</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn1_perceptron.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn1_perceptron.html</guid>
      <description>Kurze Übersicht Definition &amp;quot;Maschinelles Lernen&amp;quot; Fähigkeit zu lernen, ohne explizit programmiert zu werden. (Arthur Samuel, 1959)
Arten des Lernens Überwachtes Lernen (e.g. Klassifizierung, Regression) Unüberwachtes Lernen (e.g. Clustering, Dimensionsreduktion) Bestärkendes Lernen (e.g. Schach spielen) Formalisierung Zielfunktion $f$ Merkmalraum (input space) Ausgaberaum (output space) Datensatz $\mathcal{D}$ Hypothesenmenge $\mathcal{H}$ Lernalgorithmus $\mathcal{A}$ Das Perzeptron Ein einfaches Modell für die binäre Klassifizierung
Bilde gewichtete Summe (Linearkombination) der Merkmale Vergleiche das Ergebnis mit einem Schwellenwert Positiv, falls über dem Schwellenwert Negativ, falls unter dem Schwellenwert Gewichte und Schwellenwert sind unbekannte Parameter des Modells, die es zu lernen gilt &amp;gt; siehe Perzeptron Lernalgorithmus </description>
    </item>
    <item>
      <title>NN2 - Lineare Regression</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn2_linear_regression.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn2_linear_regression.html</guid>
      <description>Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus einem stetigen Bereich (zum Beispiel Hauspreis) Die Hypothesenfunktion ist eine gewichtete Summe der Merkmale $x_i$ plus eine Konstante $w_0$: $$h(\mathbf{x}) = \mathbf{w}^T\mathbf{x} = w_0 + w_1x_1 + w_2x_2 + \ldots + w_nx_n$$ Der Verlust (engl. loss) für einen Datenpunkt $\mathbf{x}$ ist das Fehlerquadrat: $$\mathcal{L} = (\hat{y} - y)^2 = (h(\mathbf{x}) - y)^2$$ Die Kosten (engl. cost) sind der durchschnittliche Verlust über alle Datenpunkte: $$J = \frac{1}{2m} \sum_{i=1}^{m} (\hat{y} - y)^2 = \frac{1}{2m} \sum_{i=1}^{m} (h(\mathbf{x}) - y)^2$$ Der Gradient Der Gradientenvektor $\nabla J(\mathbf{w})$ setzt sich zusammen aus den partiellen Ableitungen der Kostenfunktion $J$ nach den Gewichten $w_i$ und zeigt in jedem Punkt $\mathbf{w}$ in die Richtung des steilsten Aufstiegs: $$\nabla J = [ \partial J / \partial w_0 \quad \partial J / \partial w_1 \quad \ldots \quad \partial J / \partial w_n]^T$$ Schlussfolgerung: In die entgegengesetzte Richtung, i.</description>
    </item>
    <item>
      <title>NN3 - Logistische Regression</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn3_logistic_regression.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn3_logistic_regression.html</guid>
      <description>Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus dem stetigen Bereich $(0,1)$
Die Hypothesenfunktion ist: $$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 + w_1x_1 + w_2x_2 + \ldots + w_nx_n) \tag{1}$$
Der Kreuzentropie Verlust (engl. Cross-Entropy) für einen Datenpunkt $\mathbf{x}$: $$\mathcal{L}(a, y) = - y \log(a) - (1-y) \log(1-a)\tag{2}$$ wobei hier $a := \hat{y}$ die Vorhersage ist.
Die Kosten als durchschnittlicher Verlust über alle Datenpunkte $x^{(1)}, \ldots, x^{(m)}$: $$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$</description>
    </item>
    <item>
      <title>NN4 - Overfitting und Regularisierung</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn4_overfitting.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn4_overfitting.html</guid>
      <description>Kurze Übersicht Nichtlineare Modelle Einführung von neuen Merkmalen in Form von nichtlienaren Kombinationen der ursprünglichen Merkmale Erhöhung der Komplexität des Modells ermöglicht das Erfassen von nichtlinearen Beziehungen Bemerkung: Die Hypothesenfunktion bleibt linear in den Gewichten, es wird weiterhin logistische Regression in einem erweiterten Merkmalraum durchgeführt. Überanpassung und Regularisierung Die Überanpassung (engl. Overfitting) ist eines der häufigsten und wichtigsten Probleme in ML und DL &amp;quot;Was im Bereich des maschinellen Lernens Professionelle von Amateuren unterscheidet, ist ihre Fähigkeit mit Überanpassung umzugehen.</description>
    </item>
    <item>
      <title>NN5 - Multilayer Perzeptron</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn5_mlp.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn5_mlp.html</guid>
      <description>Kurze Übersicht Multilayer Perzeptron (MLP) Das Perzeptron kann nur linear separable Daten korrekt klassifizieren. Durch das Zusammenschließen von mehreren Perzeptronen kann man ein mehrschichtiges Perzeptron (engl. Multilayer Perceptron) aufstellen, das komplexere Funktionen modellieren kann. Ein MLP wird oft auch als Feed Forward Neural Network oder als Fully Connected Neural Network bezeichnet. Die &amp;quot;inneren&amp;quot; Schichten eines solchen Netzwerkes sind sogenannte versteckte Schichten (engl. hidden layer). Das sind alle Schichten ausgenommen die Eingangs- und Ausgangsschicht.</description>
    </item>
    <item>
      <title>NN6 - Backpropagation</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn6_backprop.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn6_backprop.html</guid>
      <description>Kurze Übersicht Forwärts- und Rückwärtslauf Im Forwärtslauf (engl. forward pass oder forward propagation) wird ein einzelner Forwärtsschritt von Schicht $[l-1]$ auf Schicht $[l]$ wie folgt berechnet: $$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]} \tag{1}$$ $$A^{[l]} = g(Z^{[l]}) \tag{2}$$ Dabei bezeichnet $g$ die Aktivierungsfunktion (z.B. Sigmoid oder ReLU).
Im Rückwärtslauf (engl. backpropagation) werden in einem einzelnen Rückwärtsschritt von Schicht $[l]$ auf Schicht $[l-1]$ die folgenden Gradienten berechnet:
$$dZ^{[l]} := \frac{\partial J }{\partial Z^{[l]}} = dA^{[l]} * g&#39;(Z^{[l]}) \tag{3}$$ $$dW^{[l]} := \frac{\partial J }{\partial W^{[l]}} = \frac{1}{m} dZ^{[l]} A^{[l-1] T} \tag{4}$$ $$db^{[l]} := \frac{\partial J }{\partial b^{[l]}} = \frac{1}{m} \sum_{i = 1}^{m} dZ^{[l](i)}\tag{5}$$ $$dA^{[l-1]} := \frac{\partial J }{\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \tag{6}$$ Dabei steht &amp;quot; $*$&amp;quot; für die elementweise Multiplikation.</description>
    </item>
    <item>
      <title>NN7 - Training &amp; Testing</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn7_training_testing.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn7_training_testing.html</guid>
      <description>Kurze Übersicht Training und Testing Der tatsächliche Erfolg eines Modells wird nicht durch niedrige Trainingskosten gemessen, sondern durch geringe Kosten auf ungesehenen Daten, d.h. hohe Vorhersagekraft, gute Generalisierung!
Die Menge aller gelabelten Daten in Trainingsset und Testset aufteilen, Testset nicht während des Trainings einsetzen!.
$E_{in}$ bezeichnet den Fehler auf dem Trainingsset, auch in-sample error. $E_{out}$ bezeichnet den Fehler auf dem gesamten Eingaberaum $X$, auch out-of-sample error. $E_{out}$ ist der eigentliche Indikator für den zukünftigen Erfolg des Modells, ist uns aber nicht zugänglich.</description>
    </item>
    <item>
      <title>NN8 - Performanzanalyse</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn8_testing.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn8_testing.html</guid>
      <description>Kurze Übersicht Performanzmetriken für Klassifizierungsprobleme Wahrheitsmatrix (engl. Confusion Matrix) Gibt eine Übersicht über die Anzahl von richtig und falsch klassifizierten Datenpunkten (bei binärer Klassifizierung) $TP =$ # True Positives $=$ Anzahl richtiger 1-Vorhersagen $FP =$ # False Positives $=$ Anzahl falscher 1-Vorhersagen $FN =$ # False Negatives $=$ Anzahl falscher 0-Vorhersagen $TN =$ # True Negatives $=$ Anzahl richtiger 0-Vorhersagen Bei Klassifizierungsproblemen mit $N$ Klassen hat man eine $N \times N$ Matrix, die in Position $(i,j)$ die Anzahl der Klasse- $j$-Beispiele enthält, die als Klasse- $i$ vorhergesagt wurden.</description>
    </item>
  </channel>
</rss>